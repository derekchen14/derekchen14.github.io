<!DOCTYPE html>
<html lang="en">
<head>

    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

    <title>Intuitive explanation of LSTM and GRU</title>
    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <link rel="stylesheet" type="text/css" href="../assets/built/screen.css%3Fv=245ecc38c2.css" />

    <meta name="description" content="So you&#x27;re studying Recurrent Neural Networks, and you&#x27;ve heard Long short term memory (LSTM) and Gated Recurrent Units (GRU) are the way to go.  How do they differ" />
    <link rel="canonical" href="index.html" />
    <meta name="referrer" content="no-referrer-when-downgrade" />
    <link rel="amphtml" href="amp/index.html" />
    
    <meta property="og:site_name" content="More Than One Turn" />
    <meta property="og:type" content="article" />
    <meta property="og:title" content="Intuitive explanation of LSTM and GRU" />
    <meta property="og:description" content="So you&#x27;re studying Recurrent Neural Networks, and you&#x27;ve heard Long short term memory (LSTM) and Gated Recurrent Units (GRU) are the way to go.  How do they differ" />
    <meta property="og:url" content="http://localhost:2368/difference-between-lstm-and-gru-for-rnns/" />
    <meta property="article:published_time" content="2016-02-19T15:25:00.000Z" />
    <meta property="article:modified_time" content="2016-03-19T14:29:17.000Z" />
    <meta property="article:tag" content="RNN" />
    
    <meta name="twitter:card" content="summary" />
    <meta name="twitter:title" content="Intuitive explanation of LSTM and GRU" />
    <meta name="twitter:description" content="So you&#x27;re studying Recurrent Neural Networks, and you&#x27;ve heard Long short term memory (LSTM) and Gated Recurrent Units (GRU) are the way to go.  How do they differ" />
    <meta name="twitter:url" content="http://localhost:2368/difference-between-lstm-and-gru-for-rnns/" />
    <meta name="twitter:label1" content="Written by" />
    <meta name="twitter:data1" content="Derek Chen" />
    <meta name="twitter:label2" content="Filed under" />
    <meta name="twitter:data2" content="RNN" />
    <meta name="twitter:site" content="@derekchen14" />
    
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name": "More Than One Turn",
        "url": "http://localhost:2368/",
        "logo": {
            "@type": "ImageObject",
            "url": "http://localhost:2368/favicon.ico",
            "width": 48,
            "height": 48
        }
    },
    "author": {
        "@type": "Person",
        "name": "Derek Chen",
        "image": {
            "@type": "ImageObject",
            "url": "//www.gravatar.com/avatar/9f3ee838eeb42849d4880676cedd85d6?s=250&d=mm&r=x",
            "width": 250,
            "height": 250
        },
        "url": "http://localhost:2368/author/derek/",
        "sameAs": []
    },
    "headline": "Intuitive explanation of LSTM and GRU",
    "url": "http://localhost:2368/difference-between-lstm-and-gru-for-rnns/",
    "datePublished": "2016-02-19T15:25:00.000Z",
    "dateModified": "2016-03-19T14:29:17.000Z",
    "keywords": "RNN",
    "description": "So if you&#x27;ve started studying RNNs, and you heard that LSTMs and GRUs at the\ntype of RNNs you should use because vanilla RNNs suffer from the vanishing\ngradient problem. That makes sense because the hidden state is passed along for\neach iteration, so when back-propagating, the same Jacobian matrix is multiplied\nby itself over and over again. If that matrix has a principal eigenvalue less\nthan one, then we have a vanishing gradient. Incidentally, if the matrix has a\nprincipal eigenvalue greater t",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "http://localhost:2368/"
    }
}
    </script>

    <meta name="generator" content="Ghost 3.29" />
    <link rel="alternate" type="application/rss+xml" title="More Than One Turn" href="../rss/index.html" />
    <style>
.page-title,
.page-description {
   color:#3D0F90!important;
   text-shadow: #F7FAEB 0px 0px 0.3em;
}
a { color: #3399ff; }  
.nav li a:after { display: none; }
.nav li:before { display: none; }
li { margin: 0.2em 0; }
ol, ul {
	margin: 0;
    position: relative;
}
ol > li, ul > li { bottom: 0; }
p { margin: 0 0 0.7em 0; }
.main-header { height: 90vh; }

article.post { width: 100%; }
section.post-full-content {
    padding: 0;
    line-height: 1em;
    font-size: 1.4em;
}
h1.site-title, h2.site-description { 
    text-shadow: 2px 2px 3px #232522;
} 
    
</style>

</head>
<body class="post-template tag-rnn">

    <div class="site-wrapper">

        

<header class="site-header">
    <div class="outer site-nav-main">
    <div class="inner">
        <nav class="site-nav">
    <div class="site-nav-left-wrapper">
        <div class="site-nav-left">
                <a class="site-nav-logo" href="../index.html">More Than One Turn</a>
            <div class="site-nav-content">
                    <ul class="nav">
    <li class="nav-home"><a href="../index.html">Home</a></li>
    <li class="nav-about"><a href="http://feature.engineering/about">About</a></li>
    <li class="nav-contact"><a href="http://feature.engineering/contact">Contact</a></li>
</ul>

                    <span class="nav-post-title dash">Difference between LSTM and GRU for RNNs</span>
            </div>
        </div>
    </div>
    <div class="site-nav-right">
            <div class="social-links">
                    <a class="social-link social-link-tw" href="https://twitter.com/derekchen14" title="Twitter" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M30.063 7.313c-.813 1.125-1.75 2.125-2.875 2.938v.75c0 1.563-.188 3.125-.688 4.625a15.088 15.088 0 0 1-2.063 4.438c-.875 1.438-2 2.688-3.25 3.813a15.015 15.015 0 0 1-4.625 2.563c-1.813.688-3.75 1-5.75 1-3.25 0-6.188-.875-8.875-2.625.438.063.875.125 1.375.125 2.688 0 5.063-.875 7.188-2.5-1.25 0-2.375-.375-3.375-1.125s-1.688-1.688-2.063-2.875c.438.063.813.125 1.125.125.5 0 1-.063 1.5-.25-1.313-.25-2.438-.938-3.313-1.938a5.673 5.673 0 0 1-1.313-3.688v-.063c.813.438 1.688.688 2.625.688a5.228 5.228 0 0 1-1.875-2c-.5-.875-.688-1.813-.688-2.75 0-1.063.25-2.063.75-2.938 1.438 1.75 3.188 3.188 5.25 4.25s4.313 1.688 6.688 1.813a5.579 5.579 0 0 1 1.5-5.438c1.125-1.125 2.5-1.688 4.125-1.688s3.063.625 4.188 1.813a11.48 11.48 0 0 0 3.688-1.375c-.438 1.375-1.313 2.438-2.563 3.188 1.125-.125 2.188-.438 3.313-.875z"/></svg>
</a>
            </div>
                <a class="rss-button" href="https://feedly.com/i/subscription/feed/http://localhost:2368/rss/" title="RSS" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><circle cx="6.18" cy="17.82" r="2.18"/><path d="M4 4.44v2.83c7.03 0 12.73 5.7 12.73 12.73h2.83c0-8.59-6.97-15.56-15.56-15.56zm0 5.66v2.83c3.9 0 7.07 3.17 7.07 7.07h2.83c0-5.47-4.43-9.9-9.9-9.9z"/></svg>
</a>

    </div>
</nav>
    </div>
</div></header>


<main id="site-main" class="site-main outer">
    <div class="inner">

        <article class="post-full post tag-rnn no-image no-image">

            <header class="post-full-header">

                <section class="post-full-tags">
                    <a href="../tag/rnn/index.html">RNN</a>
                </section>

                <h1 class="post-full-title">Difference between LSTM and GRU for RNNs</h1>


                <div class="post-full-byline">

                    <section class="post-full-byline-content">

                        <ul class="author-list">
                            <li class="author-list-item">

                                <div class="author-card">
                                    <img class="author-profile-image" src="http://www.gravatar.com/avatar/9f3ee838eeb42849d4880676cedd85d6?s=250&amp;d=mm&amp;r=x" alt="Derek Chen" />
                                    <div class="author-info">
                                        <h2>Derek Chen</h2>
                                        <p>Read <a href="../author/derek/index.html">more posts</a> by this author.</p>
                                    </div>
                                </div>

                                <a href="../author/derek/index.html" class="author-avatar">
                                    <img class="author-profile-image" src="http://www.gravatar.com/avatar/9f3ee838eeb42849d4880676cedd85d6?s=250&amp;d=mm&amp;r=x" alt="Derek Chen" />
                                </a>

                            </li>
                        </ul>

                        <section class="post-full-byline-meta">
                            <h4 class="author-name"><a href="../author/derek/index.html">Derek Chen</a></h4>
                            <div class="byline-meta-content">
                                <time class="byline-meta-date" datetime="2016-02-19">19 Feb 2016</time>
                                <span class="byline-reading-time"><span class="bull">&bull;</span> 2 min read</span>
                            </div>
                        </section>

                    </section>


                </div>
            </header>


            <section class="post-full-content">
                <div class="post-content">
                    <!--kg-card-begin: markdown--><p>So if you've started studying RNNs, and you heard that LSTMs and GRUs at the type of RNNs you should use because vanilla RNNs suffer from the vanishing gradient problem.  That makes sense because the hidden state is passed along for each iteration, so when back-propagating, the same Jacobian matrix is multiplied by itself over and over again.  If that matrix has a principal eigenvalue less than one, then we have a vanishing gradient.  Incidentally, if the matrix has a principal eigenvalue greater than one: exploding gradient.</p>
<p>To solve this problem, we would like to have gradient values that persist as they go flow backward.  And this is exactly what LSTMs do - they have a cell that stores the previous values and hold onto it unless a &quot;forget gate&quot; tells the cell to forget those values.  LSTMs also have a &quot;input gate&quot; which adds new stuff to the cell and an &quot;output gate&quot; which decides when to pass along the vectors from the cell to the next hidden state.</p>
<p>Recall that with all RNNs, the values coming in from <code>X_train</code> and <code>H_previous</code> are used to determine what happens in the current hidden state.  And the results of the current hidden state (<code>H_current</code>) are used to determine what happens in the next hidden state.  LSTMs simply add a cell layer to make sure the transfer of hidden state information from one iteration to the next is reasonably high.  Put another way, we want to remember stuff from previous iterations for as long as needed, and the cells in LSTMs allow this to happen.</p>
<p>At a high level, GRUs work the same way.  They take <code>X_train</code> and <code>H_previous</code> as inputs.  They perform some calculations and then pass along <code>H_current</code>.  In the next iteration <code>X_train.next</code> and <code>H_current</code> are used for more calculations, and so on.  What makes them different from LSTMs is that GRUs don't need the cell layer to pass values along.  The calculations within each iteration insure that the <code>H_current</code> values being passed along either retain a high amount of old information or are jump-started with a high amount of new information.</p>
<p>In the diagram below of a LSTM network, each block has two parallel lines going in and out.  The top line is the cells, the bottom line is the hidden state information.  Finally, there is a third line going in from the bottom, representing X.  In total, three inputs and two outputs. X<em>t</em>  would be <code>X_train</code>, h<em>t-1</em>  would be <code>H_previous</code>, X<em>t+1</em>  would be <code>X_train.next</code>, and h<em>t</em>  would be <code>H_current</code>.<br>
<img src="http://localhost:2368/content/images/2016/03/LSTM3-chain.png" alt="LSTM"></p>
<p>In contrast, a GRU network only has two inputs and one output (and no cell layers):<br>
<img src="http://localhost:2368/content/images/2016/03/gru.png" alt="GRU"></p>
<p><em>Images taken from <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">Understanding LSTM Networks</a></em></p>
<p>As with all intuitive/simplified explanations of complex subjects, please take with a grain of salt. Many important details have been left out.  If something I stated above is flat out wrong though, please comment and I will update - I am still learning as well.</p>
<!--kg-card-end: markdown-->
                </div>
            </section>



        </article>

    </div>
</main>

<aside class="read-next outer">
    <div class="inner">
        <div class="read-next-feed">

                <article class="post-card post tag-gpu tag-memory-error tag-deep-learning tag-theano no-image no-image">


    <div class="post-card-content">

        <a class="post-card-content-link" href="../memory-error-when-training-keras-in-aws-gpus/index.html">

            <header class="post-card-header">
                    <div class="post-card-primary-tag">gpu</div>
                <h2 class="post-card-title">Memory Error when Training in AWS GPUs</h2>
            </header>

            <section class="post-card-excerpt">
                    <p>For my Stanford Convolutional Neural Networks course, I partnered with a brilliant friend of mine to analyze images from a collection of 40,000 digitized works of art by classifying them according to artist, genre, and location.  After some standard pre-processing, we employed a</p>
            </section>

        </a>

        <footer class="post-card-meta">
            <ul class="author-list">
                <li class="author-list-item">
            
                    <div class="author-name-tooltip">
                        Derek Chen
                    </div>
            
                    <a href="../author/derek/index.html" class="static-avatar">
                        <img class="author-profile-image" src="http://www.gravatar.com/avatar/9f3ee838eeb42849d4880676cedd85d6?s=250&amp;d=mm&amp;r=x" alt="Derek Chen" />
                    </a>
                </li>
            </ul>
            <div class="post-card-byline-content">
                <span><a href="../author/derek/index.html">Derek Chen</a></span>
                <span class="post-card-byline-date"><time datetime="2016-03-07">7 Mar 2016</time> <span class="bull">&bull;</span> 4 min read</span>
            </div>
        </footer>

    </div>

</article>

                <article class="post-card post no-image no-image">


    <div class="post-card-content">

        <a class="post-card-content-link" href="../when-you-just-a-beginner-and-already-at-the-top-of-the-leaderboards/index.html">

            <header class="post-card-header">
                <h2 class="post-card-title">When you just a beginner and already at the top of the leaderboards</h2>
            </header>

            <section class="post-card-excerpt">
                    <p>A couple of days ago, I found out that I had achieved partial Internet fame! Unfortunately, it was for a negative reason due to a simple misunderstanding.  A random person took a screenshot of a Twitter exchange I had with the founder of Keras,</p>
            </section>

        </a>

        <footer class="post-card-meta">
            <ul class="author-list">
                <li class="author-list-item">
            
                    <div class="author-name-tooltip">
                        Derek Chen
                    </div>
            
                    <a href="../author/derek/index.html" class="static-avatar">
                        <img class="author-profile-image" src="http://www.gravatar.com/avatar/9f3ee838eeb42849d4880676cedd85d6?s=250&amp;d=mm&amp;r=x" alt="Derek Chen" />
                    </a>
                </li>
            </ul>
            <div class="post-card-byline-content">
                <span><a href="../author/derek/index.html">Derek Chen</a></span>
                <span class="post-card-byline-date"><time datetime="2016-01-31">31 Jan 2016</time> <span class="bull">&bull;</span> 2 min read</span>
            </div>
        </footer>

    </div>

</article>
        </div>
    </div>
</aside>




        <footer class="site-footer outer">
            <div class="site-footer-content inner">
                <section class="copyright"><a href="../index.html">More Than One Turn</a> &copy; 2020</section>
                <nav class="site-footer-nav">
                    <a href="../index.html">Latest Posts</a>
                    
                    <a href="https://twitter.com/derekchen14" target="_blank" rel="noopener">Twitter</a>
                    <a href="https://ghost.org" target="_blank" rel="noopener">Ghost</a>
                </nav>
            </div>
        </footer>

    </div>


    <script
        src="https://code.jquery.com/jquery-3.4.1.min.js"
        integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="
        crossorigin="anonymous">
    </script>
    <script src="../assets/built/casper.js%3Fv=245ecc38c2"></script>

    <script>
        // Parse the URL parameter
        function getParameterByName(name, url) {
            if (!url) url = window.location.href;
            name = name.replace(/[\[\]]/g, "\\$&");
            var regex = new RegExp("[?&]" + name + "(=([^&#]*)|&|#|$)"),
                results = regex.exec(url);
            if (!results) return null;
            if (!results[2]) return '';
            return decodeURIComponent(results[2].replace(/\+/g, " "));
        }

        // Give the parameter a variable name
        var action = getParameterByName('action');

        $(document).ready(function () {
            if (action == 'subscribe') {
                $('body').addClass("subscribe-success");
            }

            $('.subscribe-success-message .subscribe-close').click(function () {
                $('.subscribe-success-message').addClass('close');
            });

            // Reset form on opening subscrion overlay
            $('.subscribe-button').click(function() {
                $('.subscribe-overlay form').removeClass();
                $('.subscribe-email').val('');
            });
        });
    </script>

    <script>
    $(document).ready(function () {
        // FitVids - start
        var $postContent = $(".post-full-content");
        $postContent.fitVids();
        // FitVids - end

        // Replace nav with title on scroll - start
        Casper.stickyNavTitle({
            navSelector: '.site-nav-main',
            titleSelector: '.post-full-title',
            activeClass: 'nav-post-title-active'
        });
        // Replace nav with title on scroll - end

        // Hover on avatar
        var hoverTimeout;
        $('.author-list-item').hover(function () {
            var $this = $(this);

            clearTimeout(hoverTimeout);

            $('.author-card').removeClass('hovered');
            $(this).children('.author-card').addClass('hovered');

        }, function () {
            var $this = $(this);

            hoverTimeout = setTimeout(function () {
                $this.children('.author-card').removeClass('hovered');
            }, 800);
        });
    });
</script>


    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

</body>
</html>
