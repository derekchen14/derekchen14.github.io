<!DOCTYPE html>
<html lang="en">
<head>

    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

    <title>Calculating Uncertainty over Beliefs</title>
    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <link rel="stylesheet" type="text/css" href="../assets/built/screen.css%3Fv=245ecc38c2.css" />

    <link rel="canonical" href="index.html" />
    <meta name="referrer" content="no-referrer-when-downgrade" />
    <link rel="amphtml" href="amp/index.html" />
    
    <meta property="og:site_name" content="More Than One Turn" />
    <meta property="og:type" content="article" />
    <meta property="og:title" content="Calculating Uncertainty over Beliefs" />
    <meta property="og:description" content="A key sub-issue in designing conversational agents is being able to reliably calculate uncertainty over the model&#x27;s beliefs.  In doing so, the model would be able to recognize when it does not understand something, and appropriately ask for clarification.  Thus, we can imagine the output of an uncertainty model feeding" />
    <meta property="og:url" content="http://localhost:2368/calculating-uncertainty-over-beliefs/" />
    <meta property="article:published_time" content="2020-01-05T23:17:47.000Z" />
    <meta property="article:modified_time" content="2020-01-05T23:17:46.000Z" />
    <meta name="twitter:card" content="summary" />
    <meta name="twitter:title" content="Calculating Uncertainty over Beliefs" />
    <meta name="twitter:description" content="A key sub-issue in designing conversational agents is being able to reliably calculate uncertainty over the model&#x27;s beliefs.  In doing so, the model would be able to recognize when it does not understand something, and appropriately ask for clarification.  Thus, we can imagine the output of an uncertainty model feeding" />
    <meta name="twitter:url" content="http://localhost:2368/calculating-uncertainty-over-beliefs/" />
    <meta name="twitter:label1" content="Written by" />
    <meta name="twitter:data1" content="Derek Chen" />
    <meta name="twitter:site" content="@derekchen14" />
    
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name": "More Than One Turn",
        "url": "http://localhost:2368/",
        "logo": {
            "@type": "ImageObject",
            "url": "http://localhost:2368/favicon.ico",
            "width": 48,
            "height": 48
        }
    },
    "author": {
        "@type": "Person",
        "name": "Derek Chen",
        "image": {
            "@type": "ImageObject",
            "url": "//www.gravatar.com/avatar/9f3ee838eeb42849d4880676cedd85d6?s=250&d=mm&r=x",
            "width": 250,
            "height": 250
        },
        "url": "http://localhost:2368/author/derek/",
        "sameAs": []
    },
    "headline": "Calculating Uncertainty over Beliefs",
    "url": "http://localhost:2368/calculating-uncertainty-over-beliefs/",
    "datePublished": "2020-01-05T23:17:47.000Z",
    "dateModified": "2020-01-05T23:17:46.000Z",
    "description": "A key sub-issue in designing conversational agents is being able to reliably\ncalculate uncertainty over the model&#x27;s beliefs.  In doing so, the model would be\nable to recognize when it does not understand something, and appropriately ask\nfor clarification.  Thus, we can imagine the output of an uncertainty model\nfeeding into a dialogue policy manager which then decides to either retrieve an\nanswer from the knowledge base when it feels fairly certain it knows what the\ncustomer wants, or to ask a f",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "http://localhost:2368/"
    }
}
    </script>

    <meta name="generator" content="Ghost 3.29" />
    <link rel="alternate" type="application/rss+xml" title="More Than One Turn" href="../rss/index.html" />
    <style>
.page-title,
.page-description {
   color:#3D0F90!important;
   text-shadow: #F7FAEB 0px 0px 0.3em;
}
a { color: #3399ff; }  
.nav li a:after { display: none; }
.nav li:before { display: none; }
li { margin: 0.2em 0; }
ol, ul {
	margin: 0;
    position: relative;
}
ol > li, ul > li { bottom: 0; }
p { margin: 0 0 0.7em 0; }
.main-header { height: 90vh; }

article.post { width: 100%; }
section.post-full-content {
    padding: 0;
    line-height: 1em;
    font-size: 1.4em;
}
h1.site-title, h2.site-description { 
    text-shadow: 2px 2px 3px #232522;
} 
    
</style>

</head>
<body class="post-template">

    <div class="site-wrapper">

        

<header class="site-header">
    <div class="outer site-nav-main">
    <div class="inner">
        <nav class="site-nav">
    <div class="site-nav-left-wrapper">
        <div class="site-nav-left">
                <a class="site-nav-logo" href="../index.html">More Than One Turn</a>
            <div class="site-nav-content">
                    <ul class="nav">
    <li class="nav-home"><a href="../index.html">Home</a></li>
    <li class="nav-about"><a href="http://feature.engineering/about">About</a></li>
    <li class="nav-contact"><a href="http://feature.engineering/contact">Contact</a></li>
</ul>

                    <span class="nav-post-title dash">Calculating Uncertainty over Beliefs</span>
            </div>
        </div>
    </div>
    <div class="site-nav-right">
            <div class="social-links">
                    <a class="social-link social-link-tw" href="https://twitter.com/derekchen14" title="Twitter" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M30.063 7.313c-.813 1.125-1.75 2.125-2.875 2.938v.75c0 1.563-.188 3.125-.688 4.625a15.088 15.088 0 0 1-2.063 4.438c-.875 1.438-2 2.688-3.25 3.813a15.015 15.015 0 0 1-4.625 2.563c-1.813.688-3.75 1-5.75 1-3.25 0-6.188-.875-8.875-2.625.438.063.875.125 1.375.125 2.688 0 5.063-.875 7.188-2.5-1.25 0-2.375-.375-3.375-1.125s-1.688-1.688-2.063-2.875c.438.063.813.125 1.125.125.5 0 1-.063 1.5-.25-1.313-.25-2.438-.938-3.313-1.938a5.673 5.673 0 0 1-1.313-3.688v-.063c.813.438 1.688.688 2.625.688a5.228 5.228 0 0 1-1.875-2c-.5-.875-.688-1.813-.688-2.75 0-1.063.25-2.063.75-2.938 1.438 1.75 3.188 3.188 5.25 4.25s4.313 1.688 6.688 1.813a5.579 5.579 0 0 1 1.5-5.438c1.125-1.125 2.5-1.688 4.125-1.688s3.063.625 4.188 1.813a11.48 11.48 0 0 0 3.688-1.375c-.438 1.375-1.313 2.438-2.563 3.188 1.125-.125 2.188-.438 3.313-.875z"/></svg>
</a>
            </div>
                <a class="rss-button" href="https://feedly.com/i/subscription/feed/http://localhost:2368/rss/" title="RSS" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><circle cx="6.18" cy="17.82" r="2.18"/><path d="M4 4.44v2.83c7.03 0 12.73 5.7 12.73 12.73h2.83c0-8.59-6.97-15.56-15.56-15.56zm0 5.66v2.83c3.9 0 7.07 3.17 7.07 7.07h2.83c0-5.47-4.43-9.9-9.9-9.9z"/></svg>
</a>

    </div>
</nav>
    </div>
</div></header>


<main id="site-main" class="site-main outer">
    <div class="inner">

        <article class="post-full post no-image no-image">

            <header class="post-full-header">


                <h1 class="post-full-title">Calculating Uncertainty over Beliefs</h1>


                <div class="post-full-byline">

                    <section class="post-full-byline-content">

                        <ul class="author-list">
                            <li class="author-list-item">

                                <div class="author-card">
                                    <img class="author-profile-image" src="http://www.gravatar.com/avatar/9f3ee838eeb42849d4880676cedd85d6?s=250&amp;d=mm&amp;r=x" alt="Derek Chen" />
                                    <div class="author-info">
                                        <h2>Derek Chen</h2>
                                        <p>Read <a href="../author/derek/index.html">more posts</a> by this author.</p>
                                    </div>
                                </div>

                                <a href="../author/derek/index.html" class="author-avatar">
                                    <img class="author-profile-image" src="http://www.gravatar.com/avatar/9f3ee838eeb42849d4880676cedd85d6?s=250&amp;d=mm&amp;r=x" alt="Derek Chen" />
                                </a>

                            </li>
                        </ul>

                        <section class="post-full-byline-meta">
                            <h4 class="author-name"><a href="../author/derek/index.html">Derek Chen</a></h4>
                            <div class="byline-meta-content">
                                <time class="byline-meta-date" datetime="2020-01-05">5 Jan 2020</time>
                                <span class="byline-reading-time"><span class="bull">&bull;</span> 4 min read</span>
                            </div>
                        </section>

                    </section>


                </div>
            </header>


            <section class="post-full-content">
                <div class="post-content">
                    <p>A key sub-issue in designing conversational agents is being able to reliably calculate uncertainty over the model's beliefs.  In doing so, the model would be able to recognize when it does not understand something, and appropriately ask for clarification.  Thus, we can imagine the output of an uncertainty model feeding into a dialogue policy manager which then decides to either retrieve an answer from the knowledge base when it feels fairly certain it knows what the customer wants, or to ask a follow-up question when it is unsure.  From a information-theory point of view, this can be seen as a model which asks questions to minimize entropy until it reaches a certain threshold, at which point it will return an answer. Beyond improving model behavior, measuring uncertainty also gives a view into how the model is thinking for improved debugging and enhanced interpretability.</p><p>A sensible way to approach such as problem is to lean on Bayesian methods which naturally offer a distribution over its posterior beliefs.  As such, it might make sense to tackle this subject using Gaussian Processes.  A Gaussian Process is a probability distribution over a number of possible functions that fit a set of points.  In simplified terms, any point from your input X can be mapped to a corresponding label Y which is its own Gaussian variable.  For points that come from your dataset <em>x</em>, the variance of the <em>y</em> is relatively low since you know actual values that <em>y</em> can take on.  For values x̂ that are far away from your dataset, you must extrapolate in order to calculate ŷ, which should lead to Gaussian variables with high variance.  For values x* that are in between the values found in your dataset, you would expect the uncertainty of y* to be somewhere in the middle since you are merely interpolating.  Overall, each one of these points requires their own Gaussian, and thus you end up with a model composed of a multi-variate Gaussian with infinite dimensions.</p><p>Of course, you can't perform inference on an infinite number of Gaussians, so we use the kernel trick to approximate the co-variance matrix.  In slightly more detail, recall that a multivariate Gaussian can be fully described by a <em>m</em>-dimensional vector of means and a <em>m </em>x <em>m</em>  co-variance matrix.   If <em>m</em> goes towards infinity, then this matrix can be described by a kernel K(x_i, x_j).  (For more details, a simple search will return many results, my favorites: <a href="https://distill.pub/2019/visual-exploration-gaussian-processes/">Distill publication</a>, <a href="https://youtu.be/92-98SYOdlY">ICL lecture video</a> or <a href="http://cs229.stanford.edu/section/cs229-gaussian_processes.pdf">Stanford lecture notes</a>).  Next, to perform inference, you can use standard equations to extract the information you know from your dataset, typically using Cholesky decomposition, which is then used to make predictions about the unknown data.  Unfortunately, performing this calculation requires inverting a matrix the size of your dataset, which operates at a speed of O(n^3).  This can work for small problems, but quickly becomes intractable for larger datasets containing hundreds of thousands of examples.  In addition to being slow, GP also has hyper-parameters to tune (namely σ and <em>l</em>) that require some domain knowledge.  There is also the problem of choosing the right kernel in the first place to serve as the prior.  Finally, Gaussian Processes require a bit of manipulation to get them to work for classification and RL problems.</p><p>In any case, the research community has shifted towards modeling the world through deep learning, which require new ideas for calculating uncertainty because neural networks are trained with gradient descent.  Luckily, the commonplace tool of dropout can be easily adapted to fit our needs in this situation.  More concretely, suppose we have a existing model that has already been trained to convergence.  Then, during test time, we simply perturb the model using dropout for the various inputs to generate random samples of the model. In this sense, we get an ensemble of models that can be averaged to give a higher confidence prediction.  More importantly, in addition to a mean, the predictions from this set of models has variance that can be empirically calculated (<a href="http://mlg.eng.cam.ac.uk/yarin/blog_3d801aa532c1ce.html">Details here</a>).  I think the key insight here is that we are not perturbing the inputs to generate noise, but rather sampling a distribution of models.  Intuitively, this is equivalent to the distribution of functions in GP being used to fit the data.  Mathematically, this can be seen as equivalent by reviewing the derivations found in the paper by Gal and Ghahramani: <a href="https://arxiv.org/abs/1506.02142">https://arxiv.org/abs/1506.02142</a>.</p><p>Even with this method though, we still face at least a number of considerable complications before being able have dialogue models that are able to reason about uncertainty.  To start, recall that our predicted belief represents a distribution over user intents, and thus we must assume a finite ontology of intents already exists that can properly approximate the meaning of utterances.   This is a non-trivial assumption, but also outside the scope of this blog post.   However, even assuming that the previous conditions are met, the dropout method still might not be sufficient because we must run a full inference pass each time just to get one sample.  Next, to get an accurate estimate of the variance for one class, there might need thousands of samples.  Then, to get an accurate estimate for all <em>n</em> classes would need <em>n</em>-thousand samples, where for real life problems <em>n</em> itself might be around a thousand.  If we view our semantic space as continuous, then this sampling method isn't even tractable.  Perhaps we could measure our uncertainty instead as the tightness of the bounds of the samples, and anything beyond a certain range would be considered "low certainty". </p><p>With that said, note that what we really want is a tool for measuring the uncertainty over user intents in the semantic space.  More specifically, we don't just need a system where its predictions are calibrated to match the likelihood; what we really want is a system where its predictions have a semantic meaning.  In other words, we have been viewing uncertainty as a single number assigned to each class, but perhaps we should be viewing certainty as a point within an embedding space.  So for example, in the restaurant domain, when the model assigns high probability to Japanese food, it also raises the probability of Chinese and Korean food because these items are more closely grouped together in the "Asian food" cluster.  At the same time if the entity that triggered the prediction was "fish", then maybe Japanese (sashimi) and Mexican (fish tacos) should concurrently increase, while the prediction shifts away from the Korean node in the embedding space.  Consequently, notice this immediately invalidates any <a href="https://arxiv.org/abs/1505.05424">Bayesian Neural Network</a> or <a href="https://arxiv.org/abs/1608.05081">Bayes by Backprop</a> approaches that capture uncertainty over the weights of the network rather than uncertainty over the understanding.  </p><p>In this sense, rather than attaching an uncertainty score to each intent in the ontology, what we needed is an embedding space of intents that still offers a measure of uncertainty.  Then, we also need a way to calculate it.</p>
                </div>
            </section>



        </article>

    </div>
</main>

<aside class="read-next outer">
    <div class="inner">
        <div class="read-next-feed">

                <article class="post-card post no-image no-image">


    <div class="post-card-content">

        <a class="post-card-content-link" href="../deciding-when-to-ask-questions-for-dialogue/index.html">

            <header class="post-card-header">
                <h2 class="post-card-title">Deciding when to Ask Questions for Dialogue</h2>
            </header>

            <section class="post-card-excerpt">
                    <p>Performing active learning on data annotation is to decide when the model should query the expert annotator for more samples.  Note the parallel with dialogue, which is to decide when the agent should ask a clarification question to the customer for more details on</p>
            </section>

        </a>

        <footer class="post-card-meta">
            <ul class="author-list">
                <li class="author-list-item">
            
                    <div class="author-name-tooltip">
                        Derek Chen
                    </div>
            
                    <a href="../author/derek/index.html" class="static-avatar">
                        <img class="author-profile-image" src="http://www.gravatar.com/avatar/9f3ee838eeb42849d4880676cedd85d6?s=250&amp;d=mm&amp;r=x" alt="Derek Chen" />
                    </a>
                </li>
            </ul>
            <div class="post-card-byline-content">
                <span><a href="../author/derek/index.html">Derek Chen</a></span>
                <span class="post-card-byline-date"><time datetime="2020-06-28">28 Jun 2020</time> <span class="bull">&bull;</span> 3 min read</span>
            </div>
        </footer>

    </div>

</article>

                <article class="post-card post no-image no-image">


    <div class="post-card-content">

        <a class="post-card-content-link" href="../ai-as-feature-or-foundation/index.html">

            <header class="post-card-header">
                <h2 class="post-card-title">AI as Feature or Foundation</h2>
            </header>

            <section class="post-card-excerpt">
                    <p>For awhile from 2015 to 2020 it seemed as if every start-up touted itself to be powered by AI.  The buzz around artificial intelligence has faded a bit, probably because it's clear that AGI is not just around the corner and also because the</p>
            </section>

        </a>

        <footer class="post-card-meta">
            <ul class="author-list">
                <li class="author-list-item">
            
                    <div class="author-name-tooltip">
                        Derek Chen
                    </div>
            
                    <a href="../author/derek/index.html" class="static-avatar">
                        <img class="author-profile-image" src="http://www.gravatar.com/avatar/9f3ee838eeb42849d4880676cedd85d6?s=250&amp;d=mm&amp;r=x" alt="Derek Chen" />
                    </a>
                </li>
            </ul>
            <div class="post-card-byline-content">
                <span><a href="../author/derek/index.html">Derek Chen</a></span>
                <span class="post-card-byline-date"><time datetime="2020-01-01">1 Jan 2020</time> <span class="bull">&bull;</span> 3 min read</span>
            </div>
        </footer>

    </div>

</article>
        </div>
    </div>
</aside>




        <footer class="site-footer outer">
            <div class="site-footer-content inner">
                <section class="copyright"><a href="../index.html">More Than One Turn</a> &copy; 2020</section>
                <nav class="site-footer-nav">
                    <a href="../index.html">Latest Posts</a>
                    
                    <a href="https://twitter.com/derekchen14" target="_blank" rel="noopener">Twitter</a>
                    <a href="https://ghost.org" target="_blank" rel="noopener">Ghost</a>
                </nav>
            </div>
        </footer>

    </div>


    <script
        src="https://code.jquery.com/jquery-3.4.1.min.js"
        integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="
        crossorigin="anonymous">
    </script>
    <script src="../assets/built/casper.js%3Fv=245ecc38c2"></script>

    <script>
        // Parse the URL parameter
        function getParameterByName(name, url) {
            if (!url) url = window.location.href;
            name = name.replace(/[\[\]]/g, "\\$&");
            var regex = new RegExp("[?&]" + name + "(=([^&#]*)|&|#|$)"),
                results = regex.exec(url);
            if (!results) return null;
            if (!results[2]) return '';
            return decodeURIComponent(results[2].replace(/\+/g, " "));
        }

        // Give the parameter a variable name
        var action = getParameterByName('action');

        $(document).ready(function () {
            if (action == 'subscribe') {
                $('body').addClass("subscribe-success");
            }

            $('.subscribe-success-message .subscribe-close').click(function () {
                $('.subscribe-success-message').addClass('close');
            });

            // Reset form on opening subscrion overlay
            $('.subscribe-button').click(function() {
                $('.subscribe-overlay form').removeClass();
                $('.subscribe-email').val('');
            });
        });
    </script>

    <script>
    $(document).ready(function () {
        // FitVids - start
        var $postContent = $(".post-full-content");
        $postContent.fitVids();
        // FitVids - end

        // Replace nav with title on scroll - start
        Casper.stickyNavTitle({
            navSelector: '.site-nav-main',
            titleSelector: '.post-full-title',
            activeClass: 'nav-post-title-active'
        });
        // Replace nav with title on scroll - end

        // Hover on avatar
        var hoverTimeout;
        $('.author-list-item').hover(function () {
            var $this = $(this);

            clearTimeout(hoverTimeout);

            $('.author-card').removeClass('hovered');
            $(this).children('.author-card').addClass('hovered');

        }, function () {
            var $this = $(this);

            hoverTimeout = setTimeout(function () {
                $this.children('.author-card').removeClass('hovered');
            }, 800);
        });
    });
</script>


    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

</body>
</html>
